{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from duckdb import duckdb, DuckDBPyConnection\n",
    "from duckdb.typing import DuckDBPyType\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "db_path = '../data/llama.db'\n",
    "documents_path = '/Users/ada.sh/Developments/Projects/TechnicalDocsAssistant/tests/test_data/textual'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a5763eafe3749cc",
   "metadata": {},
   "source": [
    "## Data type for\n",
    "ARRAY_TYPE = DuckDBPyType(list[float])\n",
    "\n",
    "## Token size of each chunk\n",
    "CHUNK_SIZE = 1024\n",
    "\n",
    "# Token size of overlap between chunks\n",
    "CHUNK_OVERLAP = 200\n",
    "\n",
    "# HuggingFace identifier for embedding model\n",
    "MODEL_NAME = 'BAAI/bge-small-en-v1.5'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4ed7d08fa16289e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9e74f2987059803",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "def close_db(db):\n",
    "    if db is not None:\n",
    "        db.close()\n",
    "    else:\n",
    "        print('You must provide the connection to the database')\n",
    "\n",
    "def open_db(db_path: str = None, in_memory: Optional[bool] = False) -> DuckDBPyConnection:\n",
    "  if db_path is None or in_memory:\n",
    "    return duckdb.connect(':memory:')\n",
    "  return duckdb.connect(db_path)\n",
    "\n",
    "\n",
    "def load_extension(conn: DuckDBPyConnection, extension: str = 'vss') -> DuckDBPyConnection:\n",
    "    # Load any extension into duckdb\n",
    "    # For RAG, we're loading Vector Similarity Search\n",
    "  try:\n",
    "    conn.install_extension(extension)\n",
    "    conn.load_extension(extension)\n",
    "    conn.execute(\"SET GLOBAL hnsw_enable_experimental_persistence = true;\")\n",
    "  except Exception as e:\n",
    "    print(f\"Error loading extension: {e}\")\n",
    "  return conn\n",
    "\n",
    "\n",
    "def initialize_schema(conn: DuckDBPyConnection) -> None:\n",
    "  # Create documents table\n",
    "  conn.execute(\n",
    "    f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS documents (\n",
    "            id INT PRIMARY KEY,\n",
    "            file TEXT,\n",
    "            text TEXT\n",
    "        );\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "  # Create chunks table w/ relation to documents\n",
    "  conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS chunks (\n",
    "    id INT PRIMARY KEY,\n",
    "    doc_id INT,\n",
    "    chunk_text TEXT,\n",
    "    chunk_index INT,\n",
    "    FOREIGN KEY(doc_id) REFERENCES documents(id)\n",
    "    );\n",
    "  \"\"\")\n",
    "\n",
    "  # Create embeddings table w/ relation to chunks\n",
    "  conn.execute(\n",
    "    f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS embeddings (\n",
    "            chunk_id INT,\n",
    "            embedding {ARRAY_TYPE},\n",
    "            FOREIGN KEY (chunk_id) REFERENCES chunks(id)\n",
    "        );\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "# We will split the documents into 1024 tokens with 200 token overlap\n",
    "#\n",
    "# Sentence splitter prefers not to split sentences or paragraphs, where\n",
    "# possible.\n",
    "def setup_node_parser() -> SentenceSplitter:\n",
    "\n",
    "    return SentenceSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        separator=\" \",\n",
    "        paragraph_separator=\"\\n\\n\"\n",
    "    )\n",
    "\n",
    "# Insert docs into db and then process them into chunks\n",
    "def process_documents(documents: list[Document], db: DuckDBPyConnection, node_parser: SentenceSplitter) -> None:\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        db.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO documents (id, file, text)\n",
    "            VALUES (?, ?, ?)\"\"\",\n",
    "            [i, doc.metadata.get('file_path', ''), doc.text]\n",
    "        )\n",
    "\n",
    "        nodes = node_parser.get_nodes_from_documents([doc])\n",
    "\n",
    "        for chunk_idx, node in enumerate(nodes):\n",
    "            # The hacky id incrementer here should be replaced with a sequence\n",
    "            db.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO chunks (id, doc_id, chunk_text, chunk_index)\n",
    "                VALUES (( SELECT COALESCE(MAX(id), -1) + 1 FROM chunks), ?, ?, ?)\"\"\",\n",
    "                [i, node.text, chunk_idx]\n",
    "            )\n",
    "\n",
    "# Basic embedding model setup\n",
    "def setup_embedding_model() -> HuggingFaceEmbedding:\n",
    "  return HuggingFaceEmbedding(\n",
    "    model_name=MODEL_NAME,\n",
    "      device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "  )\n",
    "\n",
    "# Generate embeddings from chunks and store them\n",
    "def create_embeddings(db: DuckDBPyConnection, embedding_model: HuggingFaceEmbedding) -> None:\n",
    "\n",
    "    chunks = db.execute(\"\"\"\n",
    "    SELECT id, chunk_text FROM chunks\"\"\").fetchall()\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        chunk_id, chunk_text = chunk\n",
    "        embedding = embedding_model.get_text_embedding(chunk_text)\n",
    "\n",
    "        db.execute(\"\"\"\n",
    "        INSERT INTO embeddings (chunk_id, embedding)\n",
    "        VALUES (?, ?)\"\"\",\n",
    "                   [chunk_id, embedding])\n",
    "\n",
    "# Compare embedding of prompt against all embeddings.\n",
    "# This uses array_inner_product for normalized vectors\n",
    "# and does not yet implement an HNSW index\n",
    "def query_documentation(\n",
    "        query_text: str,\n",
    "        db: DuckDBPyConnection,\n",
    "        embed_model: HuggingFaceEmbedding,\n",
    "        top_k: int = 5,\n",
    "        similarity_threshold: float = 0.0,\n",
    ") -> list[dict]:\n",
    "\n",
    "    query_embedding = embed_model.get_text_embedding(query_text)\n",
    "\n",
    "    results = db.execute(\"\"\"\n",
    "      WITH top_matches AS (\n",
    "        SELECT\n",
    "          chunk_id,\n",
    "          array_inner_product(\n",
    "          embedding::FLOAT[384], ?::FLOAT[384]) as similarity,\n",
    "          FROM embeddings\n",
    "          ORDER BY similarity DESC\n",
    "          LIMIT ?\n",
    "      )\n",
    "      SELECT c.id as chunk_id,\n",
    "      c.chunk_text,\n",
    "      c.chunk_index,\n",
    "      c.doc_id as doc_id,\n",
    "      d.file,\n",
    "      d.text as full_doc_text,\n",
    "      m.similarity\n",
    "      from top_matches m\n",
    "      JOIN chunks c on c.id = m.chunk_id\n",
    "      JOIN documents d on d.id = c.doc_id\n",
    "      WHERE m.similarity >= ?\n",
    "      ORDER BY m.similarity DESC\n",
    "    \"\"\", [query_embedding, top_k, similarity_threshold]).fetchall()\n",
    "\n",
    "    return [\n",
    "      {\n",
    "          \"chunk_id\": row[0],\n",
    "          \"chunk_text\": row[1],\n",
    "          \"chunk_index\": row[2],\n",
    "          \"doc_id\": row[3],\n",
    "          \"file\": row[4],\n",
    "          \"document_text\": row[5],\n",
    "          \"similarity\": row[6]\n",
    "\n",
    "      }\n",
    "                  for row in results\n",
    "    ]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bdcb05006f7ba29c",
   "metadata": {},
   "source": [
    "# Initializes database connection. If in_memory is\n",
    "# set to True, duckdb will use an ephemeral in memory\n",
    "# database. If False and passed a file path, it will\n",
    "# create or open a local file-based db.\n",
    "db = open_db(db_path, in_memory=False)\n",
    "\n",
    "load_extension(db, extension='vss')\n",
    "initialize_schema(db)\n",
    "\n",
    "node_parser = setup_node_parser()\n",
    "embed_model = setup_embedding_model()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set the extensions of the files we're interested in\n",
    "required_extensions = ['.md']\n",
    "\n",
    "# Loads files recursively from a directory. SimpleDirectoryReader\n",
    "# will load the correct file readers for the files being loaded\n",
    "reader = SimpleDirectoryReader(documents_path, required_exts=required_extensions, recursive=True)\n",
    "documents = reader.load_data()\n"
   ],
   "id": "3d2b2791f767bddb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64358283cb795fb6",
   "metadata": {},
   "source": "process_documents(documents, db=db, node_parser=node_parser)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "create_embeddings(db, embed_model)\n",
   "id": "6eed8bdc2538b316",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Prompt our database with the question or request that will\n",
    "# be passed to the LLM. We create an embedding, search for\n",
    "# embeddings in the same proximity in vector space,\n",
    "# and return the top five.\n",
    "#\n",
    "# We take the doc ids to pull the right docs to pass\n",
    "results = query_documentation(\n",
    "    \"How do I create a new app in Textualize?\",\n",
    "    top_k=5,\n",
    "    db=db,\n",
    "    embed_model=embed_model,\n",
    "    similarity_threshold=0.7,\n",
    ")\n",
    "\n",
    "for r in results:\n",
    "    print(f\"\\nSimilarity: {r['similarity']:.4f}\")\n",
    "    print(f\"File: {r['file']}\")\n",
    "    print(f\"Chunk {r['chunk_index']}:\")\n",
    "    print(f\"Text: {r['chunk_text']}\")\n",
    "    print(\"---\")\n",
    "\n",
    "docs_to_send = set([r['doc_id'] for r in results])"
   ],
   "id": "3faa708aac24bd14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def query_docs(db: DuckDBPyConnection, ids: list[int]) -> list[str]:\n",
    "\n",
    "    results = db.execute(\"\"\"\n",
    "    SELECT id, file, text FROM documents WHERE id IN ?\"\"\", [ids]).fetchall()\n",
    "\n",
    "    return results"
   ],
   "id": "9517e3f14bc1e451",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "docs = query_docs(db, list(docs_to_send))",
   "id": "4ff5d44fea644c6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db.close()",
   "id": "2629cad6438b6100",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "342f6c8eb4da7786",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
